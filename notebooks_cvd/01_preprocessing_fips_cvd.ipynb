{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 01 - Preprocess FIPS Codes for CVD Mortality Data\n",
    "\n",
    "This notebook merges the CVD mortality data with FIPS codes to enable joining with other datasets (ACS, weather, livestock).\n",
    "\n",
    "The location names in IHME data are in the format \"County Name (State)\", which we parse to extract County and State, then merge with the FIPS lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fips_cvd(year):\n",
    "    \"\"\"\n",
    "    Preprocesses and merges FIPS data with CVD mortality data for a given year.\n",
    "    \n",
    "    Parameters:\n",
    "    year (int): The year of the CVD mortality data (e.g., 2012).\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Preprocessed DataFrame with CVD mortality and FIPS codes.\n",
    "    \"\"\"\n",
    "    # Fixed file paths\n",
    "    fips_path = '../data_cvd/raw/state_fips.csv'\n",
    "    cvd_path = f'../data_cvd/processed/cvd_single_year/cvd_mortality_{year}.csv'\n",
    "\n",
    "    # Load and preprocess FIPS codes\n",
    "    fips_df = pd.read_csv(fips_path, dtype={'fips': str})\n",
    "    fips_df['fips'] = fips_df['fips'].str.zfill(5)  # Ensure all FIPS codes are 5 characters\n",
    "    fips_df['State_FIPS'] = fips_df['fips'].str[:2]\n",
    "    fips_df['County_FIPS'] = fips_df['fips'].str[2:]\n",
    "    fips_df['state_full'] = fips_df['state'].map({\n",
    "        'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',\n",
    "        'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',\n",
    "        'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',\n",
    "        'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "        'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "        'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',\n",
    "        'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',\n",
    "        'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',\n",
    "        'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',\n",
    "        'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',\n",
    "        'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "    })\n",
    "\n",
    "    # Load and preprocess CVD mortality data\n",
    "    cvd_df = pd.read_csv(cvd_path)\n",
    "    \n",
    "    # Extract County and State from location_name (format: \"County Name (State)\")\n",
    "    cvd_df[['County', 'State']] = cvd_df['location_name'].str.extract(r'^(.*) \\((.*)\\)$')\n",
    "    \n",
    "    # Keep relevant columns and strip whitespace\n",
    "    cvd_df = cvd_df[['County', 'State', 'cvd_mortality_rate', 'year']].copy()\n",
    "    cvd_df['County'] = cvd_df['County'].str.strip()\n",
    "    cvd_df['State'] = cvd_df['State'].str.strip()\n",
    "\n",
    "    # Merge FIPS and CVD mortality data\n",
    "    merged_df = pd.merge(\n",
    "        cvd_df,\n",
    "        fips_df[['State_FIPS', 'County_FIPS', 'name', 'state_full', 'fips']],\n",
    "        left_on=['State', 'County'],\n",
    "        right_on=['state_full', 'name'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Rename fips column to Fips for consistency with other datasets\n",
    "    merged_df = merged_df.rename(columns={'fips': 'Fips'})\n",
    "    \n",
    "    # Drop redundant columns and return\n",
    "    return merged_df.drop(columns=['name', 'state_full'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-single",
   "metadata": {},
   "source": [
    "## Test with a Single Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 2012\n",
    "df_test = preprocess_fips_cvd(2012)\n",
    "print(f\"Shape: {df_test.shape}\")\n",
    "print(f\"Columns: {df_test.columns.tolist()}\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-missing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing FIPS codes\n",
    "missing_fips = df_test[df_test['Fips'].isna()]\n",
    "print(f\"Rows with missing FIPS: {len(missing_fips)}\")\n",
    "if len(missing_fips) > 0:\n",
    "    print(\"Sample missing rows:\")\n",
    "    print(missing_fips[['County', 'State']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-all",
   "metadata": {},
   "source": [
    "## Process All Years (2012-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loop-years",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "output_dir = '../data_cvd/processed/preprocessed_fips_cvd/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process all years\n",
    "for year in range(2012, 2020):\n",
    "    df = preprocess_fips_cvd(year)\n",
    "    df.dropna(inplace=True)\n",
    "    output_path = f'{output_dir}preprocessed_cvd_fips_{year}.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Year {year}: {len(df)} rows saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify",
   "metadata": {},
   "source": [
    "## Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated files\n",
    "files = sorted([f for f in os.listdir(output_dir) if f.endswith('.csv')])\n",
    "print(\"Generated files:\")\n",
    "for f in files:\n",
    "    filepath = os.path.join(output_dir, f)\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"  {f}: {len(df)} rows, columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the final output\n",
    "df_sample = pd.read_csv(f'{output_dir}preprocessed_cvd_fips_2012.csv')\n",
    "df_sample.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
