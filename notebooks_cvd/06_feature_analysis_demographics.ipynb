{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d04a9c2",
   "metadata": {},
   "source": [
    "# Feature Analysis: Demographics Variables\n",
    "\n",
    "## Purpose\n",
    "This notebook performs comprehensive feature analysis on the demographics variables (ACS + engineered features) to identify:\n",
    "1. **Redundant features** - highly correlated pairs (|r| > 0.85)\n",
    "2. **Multicollinearity** - VIF values indicating collinear variables\n",
    "3. **Predictive relevance** - correlation with target variable (CVD Mortality Rate)\n",
    "4. **Feature groupings** - hierarchical clustering patterns\n",
    "\n",
    "## Goal\n",
    "Make informed decisions about which features to keep/drop before modeling:\n",
    "- **Drop** one variable from highly correlated pairs\n",
    "- **Keep** the variable with stronger target correlation and lower VIF\n",
    "\n",
    "## Scope\n",
    "This notebook analyzes **demographics variables only** (~21 features):\n",
    "- Original ACS variables (13)\n",
    "- Engineered percentage features (6)\n",
    "- Population counts (2)\n",
    "\n",
    "Weather variables will be analyzed separately in the next notebook.\n",
    "\n",
    "## Output\n",
    "- Visualizations saved to: `data_cvd/outputs/feature_analysis/`\n",
    "- Publication-ready plots (high DPI, proper sizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a1a81",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style for publication quality\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Print versions for reproducibility\n",
    "print(\"Library versions:\")\n",
    "print(f\"  pandas: {pd.__version__}\")\n",
    "print(f\"  numpy: {np.__version__}\")\n",
    "print(f\"  matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"  seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a554f9",
   "metadata": {},
   "source": [
    "## 2. Setup Output Directory\n",
    "\n",
    "Create directory for saving all visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f640223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for plots\n",
    "output_dir = Path('../data_cvd/outputs/feature_analysis')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\" Output directory created: {output_dir}\")\n",
    "print(f\"  All plots will be saved here in high resolution (300 DPI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c3e30",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "\n",
    "Load the combined dataset from notebook 05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final combined dataset\n",
    "df = pd.read_csv('../data_cvd/combined_final/final_combined_all_variables.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET LOADED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"  - Rows: {df.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df.shape[1]}\")\n",
    "print(f\"  - Years: {sorted(df['Year'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3dc7f9",
   "metadata": {},
   "source": [
    "## 4. Identify Demographics Variables\n",
    "\n",
    "Extract only the demographics/ACS variables for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ae7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define demographics variables (ACS + engineered features)\n",
    "# Exclude: identifiers (County, State, Year, fips), target (CVD Mortality Rate), \n",
    "# livestock variables, and weather variables\n",
    "\n",
    "# Expected demographics columns\n",
    "demographics_cols = [\n",
    "    # Original ACS variables\n",
    "    'Median Household Income',\n",
    "    'Total Population',\n",
    "    'Gini Index',\n",
    "    'Median Age',\n",
    "    'Poverty Rate',\n",
    "    'Unemployment Rate',\n",
    "    'Disability Rate',\n",
    "    \"Bachelor's Degree or Higher (%)\",\n",
    "    \"High School Degree or Higher (%)\",\n",
    "    # Engineered percentage features\n",
    "    'White Population (%)',\n",
    "    'Hispanic Population (%)',\n",
    "    'Black Population (%)',\n",
    "    'Households with No Vehicle (%)',\n",
    "    'Rent Burden (+50% of HI)',\n",
    "    'Single Mother Families (%)'\n",
    "]\n",
    "\n",
    "# Filter to only demographics columns that exist in the dataset\n",
    "demographics_cols = [col for col in demographics_cols if col in df.columns]\n",
    "\n",
    "# Extract demographics subset\n",
    "demographics_df = df[demographics_cols + ['CVD Mortality Rate']].copy()\n",
    "\n",
    "print(\"Demographics variables identified:\")\n",
    "print(f\"  Total: {len(demographics_cols)} features\")\n",
    "print(\"\\nVariables:\")\n",
    "for i, col in enumerate(demographics_cols, 1):\n",
    "    print(f\"  {i:2}. {col}\")\n",
    "\n",
    "print(f\"\\n+ Target variable: CVD Mortality Rate\")\n",
    "print(f\"\\nSubset shape: {demographics_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77942f20",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics\n",
    "\n",
    "Overview of demographics variables: distributions, ranges, missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for missing values\n",
    "missing = demographics_df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"\\n⚠ Missing values detected:\")\n",
    "    for col in missing[missing > 0].index:\n",
    "        print(f\"  {col}: {missing[col]:,} ({missing[col]/len(demographics_df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\n✓ No missing values\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "demographics_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3ea0b",
   "metadata": {},
   "source": [
    "## 6. Inter-Feature Correlation Analysis\n",
    "\n",
    "### 6.1 Correlation Matrix Heatmap\n",
    "\n",
    "Visualize correlations between all demographics variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70452db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix (exclude target variable for now)\n",
    "corr_matrix = demographics_df[demographics_cols].corr()\n",
    "\n",
    "# Create publication-quality heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "# Create heatmap with annotations\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True,  # Show correlation values\n",
    "            fmt='.2f',   # Two decimal places\n",
    "            cmap='coolwarm',  # Diverging colormap\n",
    "            center=0,    # Center colormap at 0\n",
    "            vmin=-1, vmax=1,  # Fix scale\n",
    "            square=True,  # Square cells\n",
    "            linewidths=0.5,  # Grid lines\n",
    "            cbar_kws={'label': 'Pearson Correlation', 'shrink': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "plt.title('Demographics Variables: Correlation Matrix', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Variables', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Variables', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "plt.savefig(output_dir / 'demographics_correlation_matrix.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\" Saved: demographics_correlation_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a2979",
   "metadata": {},
   "source": [
    "### 6.2 High Correlation Pairs\n",
    "\n",
    "Identify variable pairs with |correlation| > 0.85 (indicating potential redundancy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98273a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"HIGH CORRELATION PAIRS (|r| > 0.85)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find high correlation pairs\n",
    "threshold = 0.85\n",
    "high_corr_pairs = []\n",
    "\n",
    "# Iterate through correlation matrix\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "            high_corr_pairs.append({\n",
    "                'Variable 1': corr_matrix.columns[i],\n",
    "                'Variable 2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs)\n",
    "    high_corr_df = high_corr_df.sort_values('Correlation', key=abs, ascending=False)\n",
    "    \n",
    "    print(f\"\\nFound {len(high_corr_df)} pairs with |correlation| > {threshold}:\")\n",
    "    print(\"\\n\" + high_corr_df.to_string(index=False))\n",
    "    \n",
    "    # Save to CSV\n",
    "    high_corr_df.to_csv(output_dir / 'high_correlation_pairs.csv', index=False)\n",
    "    print(f\"\\n Saved: high_correlation_pairs.csv\")\n",
    "else:\n",
    "    print(f\"\\n✓ No variable pairs with |correlation| > {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd0459",
   "metadata": {},
   "source": [
    "### 6.3 Hierarchical Clustering Dendrogram\n",
    "\n",
    "Visualize natural groupings of correlated variables using hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fd049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance matrix from correlations\n",
    "# Distance = 1 - |correlation|\n",
    "distance_matrix = 1 - np.abs(corr_matrix)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "linkage_matrix = linkage(squareform(distance_matrix), method='average')\n",
    "\n",
    "# Create publication-quality dendrogram\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "dendrogram(linkage_matrix, \n",
    "           labels=corr_matrix.columns,\n",
    "           orientation='top',\n",
    "           distance_sort='ascending',\n",
    "           show_leaf_counts=False,\n",
    "           leaf_font_size=10,\n",
    "           ax=ax)\n",
    "\n",
    "plt.title('Demographics Variables: Hierarchical Clustering Dendrogram', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Variables', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Distance (1 - |Correlation|)', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add horizontal line at threshold\n",
    "threshold_distance = 1 - threshold\n",
    "plt.axhline(y=threshold_distance, color='r', linestyle='--', \n",
    "            linewidth=2, label=f'Threshold (|r| = {threshold})')\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "plt.savefig(output_dir / 'demographics_dendrogram.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\" Saved: demographics_dendrogram.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Variables connected below the red line (threshold) are highly correlated\")\n",
    "print(\"  - Consider keeping only one representative from each tight cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8b134",
   "metadata": {},
   "source": [
    "## 7. Relationship with Target Variable\n",
    "\n",
    "### 7.1 Feature-Target Correlation\n",
    "\n",
    "Calculate correlation of each feature with CVD Mortality Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with target variable\n",
    "target_corr = demographics_df[demographics_cols].corrwith(demographics_df['CVD Mortality Rate'])\n",
    "target_corr = target_corr.sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE CORRELATION WITH TARGET (CVD Mortality Rate)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nRanked by absolute correlation:\")\n",
    "print(\"\\n\" + target_corr.to_string())\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = ['green' if x > 0 else 'red' for x in target_corr.values]\n",
    "target_corr.plot(kind='barh', color=colors, ax=ax)\n",
    "\n",
    "plt.title('Correlation with CVD Mortality Rate', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Pearson Correlation', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Demographics Variables', fontsize=12, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linewidth=1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "plt.savefig(output_dir / 'target_correlation_barplot.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\"\\n Saved: target_correlation_barplot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save to CSV\n",
    "target_corr_df = pd.DataFrame({\n",
    "    'Variable': target_corr.index,\n",
    "    'Correlation with Target': target_corr.values\n",
    "})\n",
    "target_corr_df.to_csv(output_dir / 'target_correlations.csv', index=False)\n",
    "print(\" Saved: target_correlations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad0b63",
   "metadata": {},
   "source": [
    "### 7.2 Bivariate Scatter Plots\n",
    "\n",
    "Visualize relationships between top correlated features and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35251af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 6 features by absolute correlation\n",
    "top_features = target_corr.abs().nlargest(6).index.tolist()\n",
    "\n",
    "# Create 2x3 subplot grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot with regression line\n",
    "    ax.scatter(demographics_df[feature], \n",
    "               demographics_df['CVD Mortality Rate'],\n",
    "               alpha=0.3, s=10, color='steelblue')\n",
    "    \n",
    "    # Add regression line\n",
    "    z = np.polyfit(demographics_df[feature].dropna(), \n",
    "                   demographics_df.loc[demographics_df[feature].notna(), 'CVD Mortality Rate'],\n",
    "                   1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(demographics_df[feature].sort_values(), \n",
    "            p(demographics_df[feature].sort_values()),\n",
    "            \"r--\", linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Labels and correlation\n",
    "    corr_val = target_corr[feature]\n",
    "    ax.set_xlabel(feature, fontsize=10, fontweight='bold')\n",
    "    ax.set_ylabel('CVD Mortality Rate', fontsize=10, fontweight='bold')\n",
    "    ax.set_title(f'r = {corr_val:.3f}', fontsize=11, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Top 6 Features vs. CVD Mortality Rate', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "plt.savefig(output_dir / 'top_features_scatter_plots.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\" Saved: top_features_scatter_plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbf795",
   "metadata": {},
   "source": [
    "## 8. Multicollinearity Detection (VIF)\n",
    "\n",
    "Calculate Variance Inflation Factor (VIF) for each variable.\n",
    "- **VIF < 5**: Low multicollinearity\n",
    "- **VIF 5-10**: Moderate multicollinearity\n",
    "- **VIF > 10**: High multicollinearity (problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for VIF calculation (remove any NaN values)\n",
    "vif_data = demographics_df[demographics_cols].dropna()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VARIANCE INFLATION FACTOR (VIF) ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nCalculating VIF for each variable...\")\n",
    "print(\"(This may take a minute for 15+ variables)\\n\")\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_results = []\n",
    "for i, col in enumerate(demographics_cols):\n",
    "    try:\n",
    "        vif_value = variance_inflation_factor(vif_data.values, i)\n",
    "        vif_results.append({\n",
    "            'Variable': col,\n",
    "            'VIF': vif_value\n",
    "        })\n",
    "        print(f\"  ✓ {col}: VIF = {vif_value:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {col}: Error calculating VIF ({str(e)})\")\n",
    "        vif_results.append({\n",
    "            'Variable': col,\n",
    "            'VIF': np.nan\n",
    "        })\n",
    "\n",
    "# Create VIF dataframe\n",
    "vif_df = pd.DataFrame(vif_results)\n",
    "vif_df = vif_df.sort_values('VIF', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VIF RESULTS (sorted by VIF value):\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n\" + vif_df.to_string(index=False))\n",
    "\n",
    "# Interpretation\n",
    "high_vif = vif_df[vif_df['VIF'] > 10]\n",
    "if len(high_vif) > 0:\n",
    "    print(f\"\\n⚠ {len(high_vif)} variables with VIF > 10 (high multicollinearity):\")\n",
    "    for _, row in high_vif.iterrows():\n",
    "        print(f\"  - {row['Variable']}: VIF = {row['VIF']:.2f}\")\n",
    "else:\n",
    "    print(\"\\n✓ No variables with VIF > 10\")\n",
    "\n",
    "# Save to CSV\n",
    "vif_df.to_csv(output_dir / 'vif_analysis.csv', index=False)\n",
    "print(\"\\n✓ Saved: vif_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e840f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize VIF values\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Color code by severity\n",
    "colors = ['green' if x < 5 else 'orange' if x < 10 else 'red' \n",
    "          for x in vif_df['VIF'].values]\n",
    "\n",
    "vif_df.set_index('Variable')['VIF'].plot(kind='barh', color=colors, ax=ax)\n",
    "\n",
    "plt.title('Variance Inflation Factor (VIF) by Variable', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('VIF Value', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Demographics Variables', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add reference lines\n",
    "plt.axvline(x=5, color='orange', linestyle='--', linewidth=1.5, \n",
    "            alpha=0.7, label='VIF = 5 (Moderate threshold)')\n",
    "plt.axvline(x=10, color='red', linestyle='--', linewidth=1.5, \n",
    "            alpha=0.7, label='VIF = 10 (High threshold)')\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "plt.savefig(output_dir / 'vif_barplot.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved: vif_barplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd826d4b",
   "metadata": {},
   "source": [
    "## 9. Decision Framework\n",
    "\n",
    "### 9.1 Combine All Metrics\n",
    "\n",
    "Create comprehensive table with all relevant metrics for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a949c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all metrics into one dataframe\n",
    "decision_df = pd.DataFrame({\n",
    "    'Variable': demographics_cols,\n",
    "    'Target_Correlation': [target_corr[col] for col in demographics_cols],\n",
    "    'Abs_Target_Correlation': [abs(target_corr[col]) for col in demographics_cols],\n",
    "    'VIF': [vif_df[vif_df['Variable'] == col]['VIF'].values[0] if col in vif_df['Variable'].values else np.nan \n",
    "            for col in demographics_cols]\n",
    "})\n",
    "\n",
    "# Sort by absolute target correlation (descending)\n",
    "decision_df = decision_df.sort_values('Abs_Target_Correlation', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPREHENSIVE DECISION METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n\" + decision_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "decision_df.to_csv(output_dir / 'feature_decision_metrics.csv', index=False)\n",
    "print(\"\\n✓ Saved: feature_decision_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd6c0cd",
   "metadata": {},
   "source": [
    "### 9.2 Decision Guidelines\n",
    "\n",
    "For each highly correlated pair (|r| > 0.85), apply the following decision rules:\n",
    "\n",
    "**Decision Criteria:**\n",
    "1. **Target Correlation**: Keep variable with higher |correlation| with CVD Mortality Rate\n",
    "2. **VIF**: Prefer variable with lower VIF (less multicollinearity)\n",
    "3. **Interpretability**: If metrics are similar, keep more interpretable variable\n",
    "\n",
    "**Actions:**\n",
    "- Document which variable to **KEEP** and which to **DROP**\n",
    "- Provide clear reasoning for each decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c42f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FEATURE SELECTION RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'high_corr_df' in locals() and len(high_corr_df) > 0:\n",
    "    print(f\"\\nAnalyzing {len(high_corr_df)} highly correlated pairs...\\n\")\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    for idx, row in high_corr_df.iterrows():\n",
    "        var1 = row['Variable 1']\n",
    "        var2 = row['Variable 2']\n",
    "        corr = row['Correlation']\n",
    "        \n",
    "        # Get metrics for both variables\n",
    "        var1_metrics = decision_df[decision_df['Variable'] == var1].iloc[0]\n",
    "        var2_metrics = decision_df[decision_df['Variable'] == var2].iloc[0]\n",
    "        \n",
    "        print(f\"Pair {idx+1}: {var1} vs {var2}\")\n",
    "        print(f\"  Inter-correlation: {corr:.3f}\")\n",
    "        print(f\"\\n  {var1}:\")\n",
    "        print(f\"    - Target correlation: {var1_metrics['Target_Correlation']:.3f}\")\n",
    "        print(f\"    - VIF: {var1_metrics['VIF']:.2f}\")\n",
    "        print(f\"\\n  {var2}:\")\n",
    "        print(f\"    - Target correlation: {var2_metrics['Target_Correlation']:.3f}\")\n",
    "        print(f\"    - VIF: {var2_metrics['VIF']:.2f}\")\n",
    "        \n",
    "        # Decision logic\n",
    "        var1_score = var1_metrics['Abs_Target_Correlation'] - (var1_metrics['VIF'] / 100)\n",
    "        var2_score = var2_metrics['Abs_Target_Correlation'] - (var2_metrics['VIF'] / 100)\n",
    "        \n",
    "        if var1_score > var2_score:\n",
    "            keep, drop = var1, var2\n",
    "            reason = f\"Higher target correlation ({var1_metrics['Abs_Target_Correlation']:.3f} vs {var2_metrics['Abs_Target_Correlation']:.3f})\"\n",
    "        else:\n",
    "            keep, drop = var2, var1\n",
    "            reason = f\"Higher target correlation ({var2_metrics['Abs_Target_Correlation']:.3f} vs {var1_metrics['Abs_Target_Correlation']:.3f})\"\n",
    "        \n",
    "        print(f\"\\n  → RECOMMENDATION: KEEP '{keep}', DROP '{drop}'\")\n",
    "        print(f\"    Reason: {reason}\")\n",
    "        print(\"\\n\" + \"-\" * 70 + \"\\n\")\n",
    "        \n",
    "        recommendations.append({\n",
    "            'Correlated Pair': f\"{var1} <-> {var2}\",\n",
    "            'Correlation': corr,\n",
    "            'Keep': keep,\n",
    "            'Drop': drop,\n",
    "            'Reason': reason\n",
    "        })\n",
    "    \n",
    "    # Save recommendations\n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    recommendations_df.to_csv(output_dir / 'feature_selection_recommendations.csv', index=False)\n",
    "    print(\"✓ Saved: feature_selection_recommendations.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n✓ No highly correlated pairs detected.\")\n",
    "    print(\"  All demographics features can be retained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8c87d",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "**Analysis Completed:**\n",
    "- ✓ Descriptive statistics\n",
    "- ✓ Inter-feature correlation matrix (heatmap)\n",
    "- ✓ High correlation pairs identification (|r| > 0.85)\n",
    "- ✓ Hierarchical clustering (dendrogram)\n",
    "- ✓ Feature-target correlations\n",
    "- ✓ Bivariate scatter plots (top 6 features)\n",
    "- ✓ Multicollinearity detection (VIF)\n",
    "- ✓ Decision recommendations\n",
    "\n",
    "**Output Files:**\n",
    "All visualizations and tables saved to: `data_cvd/outputs/feature_analysis/`\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review recommendations and make final decisions\n",
    "2. Proceed to weather variables analysis (next notebook)\n",
    "3. Drop selected features from combined dataset\n",
    "4. Begin machine learning modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated files\n",
    "print(\"=\" * 70)\n",
    "print(\"OUTPUT FILES GENERATED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDirectory: {output_dir}\\n\")\n",
    "\n",
    "output_files = sorted(output_dir.glob('*'))\n",
    "for file in output_files:\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"  ✓ {file.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nTotal files: {len(output_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
